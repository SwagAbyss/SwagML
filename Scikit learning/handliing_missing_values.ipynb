{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Data preprocessing\n",
    "import sklearn as sk\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Titanic-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values and their percentage: \n",
      "Column: Age - Values: 177 - Percentage: 20% - Type: float64\n",
      "Column: Cabin - Values: 687 - Percentage: 77% - Type: object\n",
      "Column: Embarked - Values: 2 - Percentage: 0% - Type: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values and their percentage: \")\n",
    "for column in data.columns:\n",
    "    if data[column].isnull().any():\n",
    "        print(f'Column: {column} - Values: {data[column].isnull().sum()} - Percentage: {round((data[column].isnull().sum())/data.shape[0]*100)}% - Type: {data[column].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numcol = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(numcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TransformerMixin.fit_transform() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimpute\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleImputer\n\u001b[1;32m      2\u001b[0m impute_mean \u001b[39m=\u001b[39m SimpleImputer(missing_values\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan, strategy\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m impute_mean\u001b[39m.\u001b[39;49mfit_transform()\n",
      "\u001b[0;31mTypeError\u001b[0m: TransformerMixin.fit_transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "impute_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "impute_mean.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[22.   38.   26.   35.   35.     nan 54.    2.   27.   14.    4.   58.\n 20.   39.   14.   55.    2.     nan 31.     nan 35.   34.   15.   28.\n  8.   38.     nan 19.     nan   nan 40.     nan   nan 66.   28.   42.\n   nan 21.   18.   14.   40.   27.     nan  3.   19.     nan   nan   nan\n   nan 18.    7.   21.   49.   29.   65.     nan 21.   28.5   5.   11.\n 22.   38.   45.    4.     nan   nan 29.   19.   17.   26.   32.   16.\n 21.   26.   32.   25.     nan   nan  0.83 30.   22.   29.     nan 28.\n 17.   33.   16.     nan 23.   24.   29.   20.   46.   26.   59.     nan\n 71.   23.   34.   34.   28.     nan 21.   33.   37.   28.   21.     nan\n 38.     nan 47.   14.5  22.   20.   17.   21.   70.5  29.   24.    2.\n 21.     nan 32.5  32.5  54.   12.     nan 24.     nan 45.   33.   20.\n 47.   29.   25.   23.   19.   37.   16.   24.     nan 22.   24.   19.\n 18.   19.   27.    9.   36.5  42.   51.   22.   55.5  40.5    nan 51.\n 16.   30.     nan   nan 44.   40.   26.   17.    1.    9.     nan 45.\n   nan 28.   61.    4.    1.   21.   56.   18.     nan 50.   30.   36.\n   nan   nan  9.    1.    4.     nan   nan 45.   40.   36.   32.   19.\n 19.    3.   44.   58.     nan 42.     nan 24.   28.     nan 34.   45.5\n 18.    2.   32.   26.   16.   40.   24.   35.   22.   30.     nan 31.\n 27.   42.   32.   30.   16.   27.   51.     nan 38.   22.   19.   20.5\n 18.     nan 35.   29.   59.    5.   24.     nan 44.    8.   19.   33.\n   nan   nan 29.   22.   30.   44.   25.   24.   37.   54.     nan 29.\n 62.   30.   41.   29.     nan 30.   35.   50.     nan  3.   52.   40.\n   nan 36.   16.   25.   58.   35.     nan 25.   41.   37.     nan 63.\n 45.     nan  7.   35.   65.   28.   16.   19.     nan 33.   30.   22.\n 42.   22.   26.   19.   36.   24.   24.     nan 23.5   2.     nan 50.\n   nan   nan 19.     nan   nan  0.92   nan 17.   30.   30.   24.   18.\n 26.   28.   43.   26.   24.   54.   31.   40.   22.   27.   30.   22.\n   nan 36.   61.   36.   31.   16.     nan 45.5  38.   16.     nan   nan\n 29.   41.   45.   45.    2.   24.   28.   25.   36.   24.   40.     nan\n  3.   42.   23.     nan 15.   25.     nan 28.   22.   38.     nan   nan\n 40.   29.   45.   35.     nan 30.   60.     nan   nan 24.   25.   18.\n 19.   22.    3.     nan 22.   27.   20.   19.   42.    1.   32.   35.\n   nan 18.    1.   36.     nan 17.   36.   21.   28.   23.   24.   22.\n 31.   46.   23.   28.   39.   26.   21.   28.   20.   34.   51.    3.\n 21.     nan   nan   nan 33.     nan 44.     nan 34.   18.   30.   10.\n   nan 21.   29.   28.   18.     nan 28.   19.     nan 32.   28.     nan\n 42.   17.   50.   14.   21.   24.   64.   31.   45.   20.   25.   28.\n   nan  4.   13.   34.    5.   52.   36.     nan 30.   49.     nan 29.\n 65.     nan 50.     nan 48.   34.   47.   48.     nan 38.     nan 56.\n   nan  0.75   nan 38.   33.   23.   22.     nan 34.   29.   22.    2.\n  9.     nan 50.   63.   25.     nan 35.   58.   30.    9.     nan 21.\n 55.   71.   21.     nan 54.     nan 25.   24.   17.   21.     nan 37.\n 16.   18.   33.     nan 28.   26.   29.     nan 36.   54.   24.   47.\n 34.     nan 36.   32.   30.   22.     nan 44.     nan 40.5  50.     nan\n 39.   23.    2.     nan 17.     nan 30.    7.   45.   30.     nan 22.\n 36.    9.   11.   32.   50.   64.   19.     nan 33.    8.   17.   27.\n   nan 22.   22.   62.   48.     nan 39.   36.     nan 40.   28.     nan\n   nan 24.   19.   29.     nan 32.   62.   53.   36.     nan 16.   19.\n 34.   39.     nan 32.   25.   39.   54.   36.     nan 18.   47.   60.\n 22.     nan 35.   52.   47.     nan 37.   36.     nan 49.     nan 49.\n 24.     nan   nan 44.   35.   36.   30.   27.   22.   40.   39.     nan\n   nan   nan 35.   24.   34.   26.    4.   26.   27.   42.   20.   21.\n 21.   61.   57.   21.   26.     nan 80.   51.   32.     nan  9.   28.\n 32.   31.   41.     nan 20.   24.    2.     nan  0.75 48.   19.   56.\n   nan 23.     nan 18.   21.     nan 18.   24.     nan 32.   23.   58.\n 50.   40.   47.   36.   20.   32.   25.     nan 43.     nan 40.   31.\n 70.   31.     nan 18.   24.5  18.   43.   36.     nan 27.   20.   14.\n 60.   25.   14.   19.   18.   15.   31.    4.     nan 25.   60.   52.\n 44.     nan 49.   42.   18.   35.   18.   25.   26.   39.   45.   42.\n 22.     nan 24.     nan 48.   29.   52.   19.   38.   27.     nan 33.\n  6.   17.   34.   50.   27.   20.   30.     nan 25.   25.   29.   11.\n   nan 23.   23.   28.5  48.   35.     nan   nan   nan 36.   21.   24.\n 31.   70.   16.   30.   19.   31.    4.    6.   33.   23.   48.    0.67\n 28.   18.   34.   33.     nan 41.   20.   36.   16.   51.     nan 30.5\n   nan 32.   24.   48.   57.     nan 54.   18.     nan  5.     nan 43.\n 13.   17.   29.     nan 25.   25.   18.    8.    1.   46.     nan 16.\n   nan   nan 25.   39.   49.   31.   30.   30.   34.   31.   11.    0.42\n 27.   31.   39.   18.   39.   33.   26.   39.   35.    6.   30.5    nan\n 23.   31.   43.   10.   52.   27.   38.   27.    2.     nan   nan  1.\n   nan 62.   15.    0.83   nan 23.   18.   39.   21.     nan 32.     nan\n 20.   16.   30.   34.5  17.   42.     nan 35.   28.     nan  4.   74.\n  9.   16.   44.   18.   45.   51.   24.     nan 41.   21.   48.     nan\n 24.   42.   27.   31.     nan  4.   26.   47.   33.   47.   28.   15.\n 20.   19.     nan 56.   25.   33.   22.   28.   25.   39.   27.   19.\n   nan 26.   32.  ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimpute\u001b[39;00m \u001b[39mimport\u001b[39;00m KNNImputer\n\u001b[1;32m      2\u001b[0m impute_KNN \u001b[39m=\u001b[39m KNNImputer()\n\u001b[0;32m----> 3\u001b[0m impute_KNN\u001b[39m.\u001b[39;49mfit_transform(data\u001b[39m.\u001b[39;49mAge)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:848\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    847\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 848\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    851\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/impute/_knn.py:226\u001b[0m, in \u001b[0;36mKNNImputer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     force_all_finite \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 226\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    227\u001b[0m     X,\n\u001b[1;32m    228\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    229\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    230\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    231\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy,\n\u001b[1;32m    232\u001b[0m )\n\u001b[1;32m    234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X \u001b[39m=\u001b[39m X\n\u001b[1;32m    235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mask_fit_X \u001b[39m=\u001b[39m _get_mask(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing_values)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 535\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    536\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    537\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:900\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 900\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    901\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    902\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    905\u001b[0m         )\n\u001b[1;32m    907\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    908\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    909\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    910\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[22.   38.   26.   35.   35.     nan 54.    2.   27.   14.    4.   58.\n 20.   39.   14.   55.    2.     nan 31.     nan 35.   34.   15.   28.\n  8.   38.     nan 19.     nan   nan 40.     nan   nan 66.   28.   42.\n   nan 21.   18.   14.   40.   27.     nan  3.   19.     nan   nan   nan\n   nan 18.    7.   21.   49.   29.   65.     nan 21.   28.5   5.   11.\n 22.   38.   45.    4.     nan   nan 29.   19.   17.   26.   32.   16.\n 21.   26.   32.   25.     nan   nan  0.83 30.   22.   29.     nan 28.\n 17.   33.   16.     nan 23.   24.   29.   20.   46.   26.   59.     nan\n 71.   23.   34.   34.   28.     nan 21.   33.   37.   28.   21.     nan\n 38.     nan 47.   14.5  22.   20.   17.   21.   70.5  29.   24.    2.\n 21.     nan 32.5  32.5  54.   12.     nan 24.     nan 45.   33.   20.\n 47.   29.   25.   23.   19.   37.   16.   24.     nan 22.   24.   19.\n 18.   19.   27.    9.   36.5  42.   51.   22.   55.5  40.5    nan 51.\n 16.   30.     nan   nan 44.   40.   26.   17.    1.    9.     nan 45.\n   nan 28.   61.    4.    1.   21.   56.   18.     nan 50.   30.   36.\n   nan   nan  9.    1.    4.     nan   nan 45.   40.   36.   32.   19.\n 19.    3.   44.   58.     nan 42.     nan 24.   28.     nan 34.   45.5\n 18.    2.   32.   26.   16.   40.   24.   35.   22.   30.     nan 31.\n 27.   42.   32.   30.   16.   27.   51.     nan 38.   22.   19.   20.5\n 18.     nan 35.   29.   59.    5.   24.     nan 44.    8.   19.   33.\n   nan   nan 29.   22.   30.   44.   25.   24.   37.   54.     nan 29.\n 62.   30.   41.   29.     nan 30.   35.   50.     nan  3.   52.   40.\n   nan 36.   16.   25.   58.   35.     nan 25.   41.   37.     nan 63.\n 45.     nan  7.   35.   65.   28.   16.   19.     nan 33.   30.   22.\n 42.   22.   26.   19.   36.   24.   24.     nan 23.5   2.     nan 50.\n   nan   nan 19.     nan   nan  0.92   nan 17.   30.   30.   24.   18.\n 26.   28.   43.   26.   24.   54.   31.   40.   22.   27.   30.   22.\n   nan 36.   61.   36.   31.   16.     nan 45.5  38.   16.     nan   nan\n 29.   41.   45.   45.    2.   24.   28.   25.   36.   24.   40.     nan\n  3.   42.   23.     nan 15.   25.     nan 28.   22.   38.     nan   nan\n 40.   29.   45.   35.     nan 30.   60.     nan   nan 24.   25.   18.\n 19.   22.    3.     nan 22.   27.   20.   19.   42.    1.   32.   35.\n   nan 18.    1.   36.     nan 17.   36.   21.   28.   23.   24.   22.\n 31.   46.   23.   28.   39.   26.   21.   28.   20.   34.   51.    3.\n 21.     nan   nan   nan 33.     nan 44.     nan 34.   18.   30.   10.\n   nan 21.   29.   28.   18.     nan 28.   19.     nan 32.   28.     nan\n 42.   17.   50.   14.   21.   24.   64.   31.   45.   20.   25.   28.\n   nan  4.   13.   34.    5.   52.   36.     nan 30.   49.     nan 29.\n 65.     nan 50.     nan 48.   34.   47.   48.     nan 38.     nan 56.\n   nan  0.75   nan 38.   33.   23.   22.     nan 34.   29.   22.    2.\n  9.     nan 50.   63.   25.     nan 35.   58.   30.    9.     nan 21.\n 55.   71.   21.     nan 54.     nan 25.   24.   17.   21.     nan 37.\n 16.   18.   33.     nan 28.   26.   29.     nan 36.   54.   24.   47.\n 34.     nan 36.   32.   30.   22.     nan 44.     nan 40.5  50.     nan\n 39.   23.    2.     nan 17.     nan 30.    7.   45.   30.     nan 22.\n 36.    9.   11.   32.   50.   64.   19.     nan 33.    8.   17.   27.\n   nan 22.   22.   62.   48.     nan 39.   36.     nan 40.   28.     nan\n   nan 24.   19.   29.     nan 32.   62.   53.   36.     nan 16.   19.\n 34.   39.     nan 32.   25.   39.   54.   36.     nan 18.   47.   60.\n 22.     nan 35.   52.   47.     nan 37.   36.     nan 49.     nan 49.\n 24.     nan   nan 44.   35.   36.   30.   27.   22.   40.   39.     nan\n   nan   nan 35.   24.   34.   26.    4.   26.   27.   42.   20.   21.\n 21.   61.   57.   21.   26.     nan 80.   51.   32.     nan  9.   28.\n 32.   31.   41.     nan 20.   24.    2.     nan  0.75 48.   19.   56.\n   nan 23.     nan 18.   21.     nan 18.   24.     nan 32.   23.   58.\n 50.   40.   47.   36.   20.   32.   25.     nan 43.     nan 40.   31.\n 70.   31.     nan 18.   24.5  18.   43.   36.     nan 27.   20.   14.\n 60.   25.   14.   19.   18.   15.   31.    4.     nan 25.   60.   52.\n 44.     nan 49.   42.   18.   35.   18.   25.   26.   39.   45.   42.\n 22.     nan 24.     nan 48.   29.   52.   19.   38.   27.     nan 33.\n  6.   17.   34.   50.   27.   20.   30.     nan 25.   25.   29.   11.\n   nan 23.   23.   28.5  48.   35.     nan   nan   nan 36.   21.   24.\n 31.   70.   16.   30.   19.   31.    4.    6.   33.   23.   48.    0.67\n 28.   18.   34.   33.     nan 41.   20.   36.   16.   51.     nan 30.5\n   nan 32.   24.   48.   57.     nan 54.   18.     nan  5.     nan 43.\n 13.   17.   29.     nan 25.   25.   18.    8.    1.   46.     nan 16.\n   nan   nan 25.   39.   49.   31.   30.   30.   34.   31.   11.    0.42\n 27.   31.   39.   18.   39.   33.   26.   39.   35.    6.   30.5    nan\n 23.   31.   43.   10.   52.   27.   38.   27.    2.     nan   nan  1.\n   nan 62.   15.    0.83   nan 23.   18.   39.   21.     nan 32.     nan\n 20.   16.   30.   34.5  17.   42.     nan 35.   28.     nan  4.   74.\n  9.   16.   44.   18.   45.   51.   24.     nan 41.   21.   48.     nan\n 24.   42.   27.   31.     nan  4.   26.   47.   33.   47.   28.   15.\n 20.   19.     nan 56.   25.   33.   22.   28.   25.   39.   27.   19.\n   nan 26.   32.  ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "impute_KNN = KNNImputer()\n",
    "impute_KNN.fit_transform(data.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. , 4. ],\n",
       "       [3. , 4. , 3. ],\n",
       "       [5.5, 6. , 5. ],\n",
       "       [8. , 8. , 7. ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "X = [[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7]]\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
